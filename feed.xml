<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://joebakcoleman.com/feed.xml" rel="self" type="application/atom+xml"/><link href="https://joebakcoleman.com/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-09-26T02:17:00+00:00</updated><id>https://joebakcoleman.com/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">I did not want to write this blog post.</title><link href="https://joebakcoleman.com/blog/2024/protzko/" rel="alternate" type="text/html" title="I did not want to write this blog post."/><published>2024-09-24T23:36:10+00:00</published><updated>2024-09-24T23:36:10+00:00</updated><id>https://joebakcoleman.com/blog/2024/protzko</id><content type="html" xml:base="https://joebakcoleman.com/blog/2024/protzko/"><![CDATA[<h1 id="the-preregistration-revelation">The Preregistration Revelation</h1> <p>I did not want to write this blog post. I hate when science gets resolved by blog and thread. This is why I emailed the authors in November of last year. I shared very detailed concerns and offered to walk them through those concerns so they could retract on their own terms. They declined. Instead, I got the runaround familiar to anyone asking for data available upon request. This was frustrating but not yet alarming. What really concerned me was this post by Brian Nosek:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/nosekbegins.png" sizes="95vw"/> <img src="/assets/img/nosekbegins.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>To anyone reading, this seems like a quite reasonable narrative. After all, it isn’t a grave sin to forget to preregister a descriptive analysis or two. From my perspective, it was quite different. I had emailed the authors and provided a very clear outlined draft and code comparison indicating that virtually none of the analyses matched the preregistration. One or two analyses is a mistake, the entire main text is a <em>problem</em>. Brian had to have known the issues were much more substantial than he let on, and posted in a way that minimized the seriousness of the issues.</p> <p>I still did not want to write this blog post, but I no longer felt confident the authors would earnestly evaluate the concerns. I wrote a dozen pages carefully detailing the issues and privately shared them with the editors. This was entirely distinct from the Matters Arising. Berna was not involved. I asked that my role in sharing these concerns not be made public, although said it could be shared with the authors to facilitate resolution. I though perhaps the gravity would convince them to engage with the concerns and voluntarily retract. They did not. They did, however, upload a large trove of historical documentation as part of the investigation I was not privy too.</p> <p>Examining these new files confirmed my concerns and raised many, many more. We wound up <em>way</em> past concerns they forgot to preregister. I felt compelled to send an additional write-up of my findings to the editors. For those unfamiliar with the process, I had heard nothing back about anything the authors or experts reviewing the concerns had said or contributed. Late this summer, I was informed that the investigation had concluded and they found my concerns were well-founded. The paper was retracted not over the issue of preregistration, but over a much deeper set of concerns that raise serious ethical questions and most importantly undermine the claims of the paper.</p> <p>At this point, I thought surely the authors would own up to their mistakes and I would not have to write this blog post. All along, I have hoped the authors would acknowledge their mistakes and move on. I held out some shred of belief that people who have built careers on honesty, transparency, and openness could be honest, open, and transparent. I was naive.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/nosek.png" sizes="95vw"/> <img src="/assets/img/nosek.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>They are misrepresenting the reason for retraction. They’re presenting it as a minor procedural issue with a sentence describing what was preregistered, and some deviations they failed to disclose. Worse, people on social media are believing this and applauding them for their honesty and contrition. Yet this is all bullshit and spin. The paper would not have been retracted, nor would I have raised concerns, if this was the only issue. It wouldn’t have taken 10 months and twenty pages of documentation.</p> <p>Mostly, I don’t have the time to write this. I work a 9-to-5, am writing a book, and have science to do. My website broke so I’ve slapped it up temporarily on a placeholder website… I don’t have time to fix it. I suspect the editors, my co-authors, reviewers, and ethics board members who spent countless hours trying to understand what the authors did and correct the record felt much the same. <a href="https://en.wikipedia.org/wiki/Brandolini%27s_law">Brandolini’s law</a> in full force. I am writing it because it is only fair to their time to share this, given the authors unwillingness to portray what happened honestly.</p> <p>Because I’m short on time you’ll find typos. You may find errors. You may need to dig around on their OSF to verify things. Most of the relevant files can be found in this <a href="https://osf.io/rnvxk">zip</a> which tragically I cannot link to individually. If you’re wondering whether you can trust this, I can safely say this is a subset of the things I shared with the editors and I have heard and seen nothing from the authors or team at NHB to suggest anything I raise here is incorrect.</p> <p><em>Without further ado</em></p> <h1 id="calling-bullshit">Calling Bullshit</h1> <p>If you read the <a href="https://www.nature.com/articles/s41562-024-01997-3">retraction note</a>, the editors do not mince words about why this study was retracted:</p> <ol> <li>“lack of transparency and misstatement of the hypotheses and predictions the reported meta-study was designed to test”</li> <li>“lack of preregistration for measures and analyses supporting the titular claim (against statements asserting preregistration in the published article)”</li> <li>“selection of outcome measures and analyses with knowledge of the data”</li> <li>“incomplete reporting of data and analyses.”</li> </ol> <p>How could a sentence describing all analyses as preregistered result in anything beyond the 2nd reason given? Why would a journal make such strong statements over a sentence and a few deviations? No paper has ever been retracted—if even corrected—for issues that small. Let’s go through these one by one, as these reasons are what the authors have long described as questionable research practices (QRPs).</p> <p>The first is <strong>Outcome Switching</strong>. The authors switched the decade-long-planned outcome of the study from an null finding for a supernatural phenomenon to one on replication discovered after analysis that affirmed their long-standing advocacy and was <a href="https://www.cos.io/blog/the-reforms-are-working">marketed to funders.</a></p> <p>The second issue is <strong>Falsification</strong>. They repeatedly—even in the note they just published—made false claims about their research process. We often think of falsifying data, but false claims about study methodology–including preregistration—is falsification.</p> <p>The third is <strong>HARKing</strong>. They analyzed their data, noticed a descriptive result and wrote the paper around it. They conducted statistical tests after having viewed the data that they are still claiming were preregistered (see below).</p> <p>The final issue is <strong>selectively reporting</strong> of analyses and data. They have utterly refused to provide essential insight into their piloting phase, despite the issue having been raised at least four years ago in peer review and again during the investigation. The relevant repositories remain private.</p> <p>If you simply read the retraction notice the journal put out rather than the authors’ statement it is clear <strong>the paper was rejected because the authors were found to have engaged extensively in QRPs</strong>. Of course questionable research practices are <em>questionable</em> but when a group of experts on the subject engage in them repeatedly to push a claim they fundraise on it makes you start to question. It is very important to realize that, much like a business school professor selling books based on fraud… several key authors have every reason to generate and protect this finding.</p> <h1 id="feeling-not-so-hot-honest-open-and-transparent">Feeling Not so HOT (Honest, Open and Transparent)</h1> <p>In the authors’ recently released <a href="https://osf.io/4k5sf">OSF post mortem</a>, Brian seems to suggest that the problems mostly surrounded a single line in the paper. Tellingly their explanation requires no engagement with the substance of the retraction notice or the matters arising. Instead, he focuses on something we mention only in passing. Something much less ethically fraught that he has been saying since November of last year. The inaccuracy of this line in their paper:</p> <blockquote> <p>“All confirmatory tests, replications and analyses were preregistered both in the individual studies (Supplementary Information section 3 and Supplementary Table 2) and for this meta-project (https://osf.io/6t9vm).”</p> </blockquote> <p>Read the authors’ post mortem in contrast with the journal’s exact language for why the retraction occurred. It is downright deceptive to describe the retraction as primarily a result of this sentence. The issue they highlight as the cause for retraction is only a minor point that could have been fixed with a correction. No one, myself included, felt this line alone was cause enough to retract from the beginning. It would not have taken ten months and four reviewers to sort this out. I understand that if authors disagree with the retraction—most authors of most retractions do—yet this is no excuse for failing to engage substantively with the journal’s rationale and create the impression the cause was quite different.</p> <p>The authors post-game write-up, along with spinning an offer to submit a fresh manuscript to fresh peer review as an R&amp;R has been very effective spin. Commentators on twitter appear to think this just isn’t a big deal. Everyone is making a mountain out of a molehill and the authors are setting a good example by “retracting, revising and resubmitting”</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/spin.jpeg" sizes="95vw"/> <img src="/assets/img/spin.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>What is striking is that <strong>even now</strong> the authors are choosing to obfuscate what they actually preregistered. Later in <a href="https://osf.io/2s94g/">the note</a>, they explain how this specific language came about and highlight that elsewhere they’ve described things accurately:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/manyconfirmatory.png" sizes="95vw"/> <img src="/assets/img/manyconfirmatory.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>“Many” might leave you with the impression that this section accurately described the preregistered analyses. Nope. Let’s take the very first analysis in that confirmatory analysis section. It describes a multi-level meta-analysis that was coded up by James Pustejovsky:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/confirmatoryanalysis.png" sizes="95vw"/> <img src="/assets/img/confirmatoryanalysis.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>You can even check out the <a href="https://osf.io/938rv/">pre-registered analysis code which describes this analysis as exploratory</a>. As a fun aside, this preregistered code was developed by a <a href="https://osf.io/rnvxk">paid consultant</a> they hired to provide feedback on the pre-registration and develop the pre-registration code. There’s a whole <a href="https://osf.io/rnvxk">version history</a> ostensibly created without access to data leading up to the presentation of results at Metascience 2019. Importantly, none of this code was released with original manuscript and only came to light after I raised the issue when sumbitting my concerns for investigation. So somehow in addition to forgetting what exactly they preregistered when writing it up, they forgot entirely that about this whole side-plot with a consultant they paid (who became a co-author) and just neglected to upload the code which would have made it much more obvious that the analyses were not preregisterd. What bad luck!</p> <p>Returning to the meta-analysis.</p> <p>You know how we really know this meta-analysis is exploratory though? Because <a href="https://osf.io/rnvxk">an old version</a> of the paper clearly indicates they added this analysis in March of 2020 (“Decipfhering the Decline Effect P6_JEP.docx”)—well after Schooler <a href="https://www.youtube.com/watch?v=TUiUA5O0PFk">gave a talk</a> on a preliminary analysis of the data. Conducting an analysis after having analyzed the data and observed pattern is, by the authors own definitions, <a href="https://www.pnas.org/doi/10.1073/pnas.1708274114">not a confirmatory test</a>. It’s a QRP to present it as one. It’s worth highlighting that this meta-analysis is different from their analysis of variation in replicability across labs across labs, which their correction notice indicates was <em>also</em> exploratory and relabeled as confirmatory…</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pustejovsky.png" sizes="95vw"/> <img src="/assets/img/pustejovsky.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Hell, later in their published post-mortem they (maybe?) allude to this analysis not being preregistered by saying that “some sensitivity and heterogeneity analyses” were not preregistered. But that doesn’t fix the earlier language which seems to imply this section described the preregistered analyses. Perhaps what they were thinking of was the section of <a href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41562-023-01749-9/MediaObjects/41562_2023_1749_MOESM1_ESM.pdf">their supplement</a> called “pre-registered analyses” which <em>does</em> describe the preregistration accurately. Unfortunately this is within a section also called conformatory analyses which misleadingly claims that the replication rate and the exploratory-turned-confirmatory lab-specific variation were confirmatory. Why does this section differ from the main text? Who knows? Might be hard to keep your story straight about what you preregistered if you’ve abandoned your prereg long ago.</p> <p>All this is to say that if they mistakenly described what was preregistered, they did it in three distinct places and forgot to upload the code corresponding to the actually preregistered analysis which they describe accurately in the supplement. None of the authors managed to notice this, or the fact that the paper contained multiple inconsistent descriptions of what was preregistered. I don’t care if they had a secret desire to analyze replicablity, in what world do more than a dozen experts–two of whom built platforms to make it easy and careers on encouraging it—forget what they preregistered this severely.</p> <p>Hanlon’s razor is having a hard time with this one. I really don’t know if it’s more alarming if they intentionally mislead the readers or if a team of experts on preregistration can’t even notice if the two sections labeled confirmatory analyses are consistent—and match what they paid a consultant to develop. Unethical behavior here could be limited to this paper or maybe the papers of a few key authors. Yet if this is the extent to which this group of <em>experts</em> can check their own manuscript in revision for three years for <em>internal</em> consistency… even after the paper has been retracted… there is a mountain of literature someone needs to go back and check.</p> <h1 id="it-is-not-just-about-the-preregistration">It is not just about the preregistration</h1> <p>Hopefully the above makes it dreadfully clear that either the authors are either unable or unwilling to be honest, open and transparent about what they preregistered, even now. Yet if this had just been a need to clarify which analyses were exploratory, we would have seen a correction in January and this whole thing would be a distant memory The paper was retracted for many more reasons, a small subset of the easiest to explain are described below.</p> <h2 id="outcome-switching-and-lying-by-omission">Outcome Switching and lying by omission.</h2> <p>One of the key reasons this paper was retracted is that the authors do not accurately describe their original, pre-registered motivation for the study. It is one thing to forget to preregister but it is entirely different to simply switch outcomes and pretend you were studying that thing all along.</p> <p>Stephanie Lee’s story covers the <a href="https://www.chronicle.com/article/this-study-was-hailed-as-a-win-for-science-reform-now-its-being-retracted">supernatural hypothesis</a> that motivated the research and earned the funding from a parapsychology-friendly funder. Author Jonathan Schooler had long ago proposed that merely observing a phenomenon could change its effect size. Perhaps the other authors thought this was stupid, but that’s a fantastic reason to either a) not be part of the project or b) write a separate preregistration for what <em>you</em> predict. We can see how the manuscript evolved to obscure this motivation for the study. The authors <em>were</em> somewhat transparent about their unconventional supernatural explanation in the early drafts of the paper from 2020:</p> <blockquote> <p>“According to one theory of the decline effect, the decline is caused by a study being repeatedly run (i.e., an exposure effect)25. According to this account, the more studies run between the confirmation study and the self-replication, the greater the decline should be.”</p> </blockquote> <p>This is nearly verbatim from the preregistration:</p> <blockquote> <p>According to one theory of the decline effect, the decline is caused by a study being repeatedly run (i.e., an exposure effect). Thus, we predict that the more studies run between the confirmation study and the self-replication, the greater will be the decline effect.</p> </blockquote> <p>It is also found in <a href="https://osf.io/rnvxk">responses to reviewers</a> at Nature, who sensed the authors were testing a supernatural idea even though they had reframed things towards replication by this point:</p> <blockquote> <p>“The short answer to the purpose of many of these features was to design the study a priori to address exotic possibilities for the decline effect that are at the fringes of scientific discourse….”</p> </blockquote> <p>As an aside, it’s wild to call your co-authors and funder the fringes of scientific discourse. Why take money from and work with cranks? Have some dignity. Notably, perhaps to keep the funders happy, they were generous enough to keep this idea around in the in the name of their OSF repo and the <a href="https://osf.io/rnvxk">original title</a>:</p> <blockquote> <p>The replicability of newly discovered psychological findings over repeated replications</p> </blockquote> <p>It’s also in their <a href="https://osf.io/rnvxk">original discussion</a>:</p> <blockquote> <p>Importantly, the number of times the initial investigators replicated an effect themselves is not predictive of the replicability of the effect by independent teams (Kunert, 2016).</p> </blockquote> <p>This utterly batshit supernatural framing erodes en route to the the published manuscript. Instead, the authors refer to these primary hypotheses that date back to the origin of the project as phenomena of secondary interest and do not describe the hypotheses and mechanisms explicitly. They refer only to this original motivation in the supplement of “test of unusual possible explanations.”</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/secondaryinterest.png" sizes="95vw"/> <img src="/assets/img/secondaryinterest.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Why not? Well, no need to speculate. The authors say exactly why in their response to Tal Yarkoni who asked them in review at Nature to come out and say it if they were testing a supernatural hypothesis. They decided to just change the message of the paper.</p> <blockquote> <p>“As such we revised the manuscript so as not to dwell on the decline effect hypotheses and kept that discussion and motivation for the design elements to the SOM.”</p> </blockquote> <p>It’s fine to realize your idea was bad, but something else to try bury it in the supplement and write up a whole different paper you describe in multiple places as being preregistered and what you set out to study. Peer review is no excuse for misleading readers just to get your study published because the original idea you were funded to study was absurd.</p> <p>Nevertheless, when you read the paper, you’d have no idea this is what they got funding to study. Their omitted variables and undisclosed deviations in their main-text statistical models make it even harder to discern they were after the decline effect. They were only found in the pre-registered analysis code which was made public during the investigation.</p> <p>In distancing themselves for <a href="https://www.fetzer-franklin-fund.org/projects/deciphering-the-decline-effect-1/">two of the three reasons they got funding</a> they mislead the reader about what they set out to study and why. This isn’t a preregistration issue. This is outcome switching, and lying. It’s almost not even by omission because they say it’s the fringes of scientific discourse but it’s the senior author on the paper!</p> <p>The third reason they note in early documents, most closely aligned with their goals is the “creation of a gold standard” for conducting research. While this very much aligns with the message of the paper, it is really important to note that the evaluation criteria boils down to if they fail to observe the supernatural effect they’ll have succeeded. It’ like arguing that if I don’t find a unicorn today, I’ve solved cold fusion. See our matters arising if you want to sort out why this is bad logic.</p> <p>The authors seem to indicate in their post-mortem analysis that they had planned this framing and analysis all along. If so, it’s damn surprising that none of this came up in the investigation. Why not include a link to literally any evidence of the claims in this paragraph? You think if you’re on the hook for outcome switching and HARKing you could toss in a URL to provide evidence to the contrary.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bestlaidplans.png" sizes="95vw"/> <img src="/assets/img/bestlaidplans.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Perhaps they’re referring to their <a href="https://osf.io/ahdy7/files/osfstorage">operations manual</a> but I certainly hope not. There is no plan in that document that matches the description above. If you think the decline thing is absurd and you’re just doing this to study replication… why not mention what you’re going to measure it in any of the dozen versions of the operations manual or the two pre-registrations? Instead, Here’s their early predictions, make of them what you will:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/predictions.png" sizes="95vw"/> <img src="/assets/img/predictions.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>If there is some time-stamped documentation that clearly states a desire to measure replicability—much less how they’ll do so—I cannot fathom why they did not produce it during the investigation or when I reached out in November. Perhaps it exists, but other evidence suggests otherwise. What evidence? Well, I’m glad you asked.</p> <h2 id="harking-hacking-and-cherry-picking">HARKing, Hacking and Cherry-Picking</h2> <p>What really chaps my ass about the tweet indicating this is a procedural error is that it some how ignores their decade of arguing that failing to preregister risks analyses that are conditioned on chance patterns in the data. If you alter your analysis in response to data to acheive a desired result, that result is less trustworthy. Isn’t that the whole story? And sure, exploratory research has value but repeatedly claiming your exploratory data-dependent research is confirmatory is a big, big problem. As <a href="https://www.pnas.org/doi/10.1073/pnas.1708274114">Nosek 2018 put it</a>:</p> <blockquote> <p>“Why does the distinction between prediction and postdiction matter? Failing to appreciate the difference can lead to overconfidence in post hoc explanations (postdictions) and inflate the likelihood of believing that there is evidence for a finding when there is not. Presenting postdictions as predictions can increase the attractiveness and publishability of findings by falsely reducing uncertainty.”</p> </blockquote> <p>By extension, repeatedly claiming that you’re doing prediction when you’re doing postdiction misleads your audience into believing you found more than you did. It’s deceptive and it is wrong.</p> <p>So did they alter their analysis in response to data? Sure seems like it.</p> <p>Replicability was not found in the original preregistration. Nor is it found in the <a href="https://osf.io/rnvxk">analysis code dated 09/03/2019</a>. The first mention of estimating replicability was during Schooler’s talk on 09/05/2019, which estimated replicability as the proportion of significant results among the studies with significant confirmatory tests.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/schoolertalk.png" sizes="95vw"/> <img src="/assets/img/schoolertalk.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>As with past work, they do not emphasize this rate for null confirmatory tests. Instead, they seemed <em>surprised</em> by the rate of significance for null findings. Schooler frames it as an <em>incline effect</em>.</p> <p>Between Schooler’s talk and the first draft of the write-up they wind up with <a href="https://osf.io/rnvxk">this abstract and general set of conclusions</a> from their analysis:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/originalabstract.png" sizes="95vw"/> <img src="/assets/img/originalabstract.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>This abstract for the earliest version of the manuscript states the replication rate is 92.2% (59/64) based on a definition that considers null replications of null confirmatory studies as “successful”.</p> <p>There are a few things to note. Their original conclusion is that “high-powered pre-registered studies can be effectively replicated by high-powered pre-registered replications”. This makes sense because they are replicating the confirmatory studies in the original drafts framing—which were high powered. In the published version they’ve broadened this conclude that “This high replication rate justifies confidence in rigour-enhancing methods to increase the replicability of new discoveries.” Where did that framing come from? If this was the goal all along you’d think whoever wrote this draft would be aware.</p> <p>Their definition of replicability used in the final version is not referred to here as replicability but simply statistically significant results. The reason they’re not calling this replicability is because initially they’re considering the outcome of the confirmatory study when estimating replicability. This accounts for the “highly powered pre-registered studies” language in their original abstract.</p> <p>The trouble is that this 92.2% appears to be a mathematical error, as it includes 47 of the 52 replications of significant confirmatory studies and appears to include all 12 replications of null confirmatory studies regardless of outcome. When corrected, this definition would produce a replicability rate would be 79% (51/64). This would be considerably lower than this drafts’ chosen method of calculating statistical power (~100%), and lower than replicability in the published version (86%). It would also be lower than the highest estimates from the literature cited in the initial version and later omitted for reasons unstated (11/13 or 85% from Klein et al 2014). These are the two arguments they based the title on and they fall apart once you fix this little calculation error.</p> <p>But that shiny 84.4% rate of significance is sitting right there! So now, it’s no longer the confirmatory studies they’re replicating but the predicted direction from the pilots they refuse to make public. This gets around the “incline effect” and awkwardness of cases like the Redemption study’s apparent direction reversal. The trouble is that this is not a metric anyone would plan <em>a priori</em> because it is far too sensitive to the base rate. Imagine they had only found 8 “true” findings. 100% significant results in replication for these true findings and 100% replication nulls for the null confirmatory studies. Their measure would indicate 50% replicability—the same as they say is typical in the literature. When you have perfect agreement between statistical decisions arising from replications and confirmations this metric just winds up just measuring the base rate. If it’s 10%? Replicability is 10%. This measure only indicates high replicability because the base rate is so high.</p> <p>Ok, but its not just this choice of measure that is a problem. As versions go on, they do a few things to bring their replicability above their power and the replicability in the literature. First, they revise their estimate of statistical power in a very strange way such that statistical power is zero when the sign of confirmatory test differs from predicted value even though the tests are two-tailed and the theoretical minimum is 5%. They lump in the near-1.0 statistical power estimates for significant confirmatory studies with this weird, at times zero, measure for null studies and goose statistical power down below their absurd and clearly opportunistic replicability estimate. Taken together, their claim that their rate of replication exceeds the theoretical maximum only arises as a result of jointly evolving their estimate of power and replicability. This is hacking statistics to make a claim.</p> <p>Finally, they even alter what they define as the literature-wide rate of replicability they compare against. A key claim is that they observed high replicability and the literature has not. In the main text cite a range of replicability (30-70%) which they seem to average at 50%. You might think the approximately 50% here is just the halfway point between 30 and 70. Nope, the talk by [Schooler] lays out their original math.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/fortyseven.png" sizes="95vw"/> <img src="/assets/img/fortyseven.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>There are plenty of problems with this, not the least of which is that several of these studies involve non-random sampling frames and the estimate of replicability is a result of the chosen mix of well-replicated and novel findings. But the real rub is Many Labs 1. 10 out of 13 is 77%. In reality it’s <a href="https://econtent.hogrefe.com/doi/10.1027/1864-9335/a000178">11 out of 13</a> or 85% using their criteria of significance. Ooops, high replicability was achieved a decade ago replicating the open literature. Can’t have that.</p> <p>From the initial analysis to subsequent versions, they cite ML2 and ML3 but all of a sudden leave out this study which would have undermined that claim they were higher than the disappointing range in the literature. Their 92.2% might have looked better, but the 86% is right there with it. They also opt to leave out <a href="https://journals.sagepub.com/doi/abs/10.1177/0956797619831612">Soto 2019</a> which has 87% successful replicability. It’s hard to make a claim that rigor-enhancing techniques are necessary for replicability when two other studies have replicated portions of the literature at similar rates which most assuredly did not embrace these techniques in discovery. Perhaps they didn’t know Soto’s work, but they certainly knew Many Labs 1. The two projects shared authors. If there was some justified reason for selectively excluding mid write-up the one study in the literature that makes it impossible for them to make the claim… that would be a stroke of luck. They seemed to have invented the informal comparison equivalent of selective removing of outliers. Maybe they’d argue it’s not a QRP because it isn’t a formal statistical test, but that didn’t stop them from anchoring the titular claim on this comparison.</p> <p>So they cherry-picked their point of comparison, selectively omitted two conflicting points of comparison from their original framing, and hacked their estimates of power and replicability to be near one another. We really don’t have to speculate that they cherry-picked. They come out and say the quiet part loud in an <a href="https://osf.io/rnvxk">earlier draft</a>. Here, their 75% confidence interval is lower than their their other metrics and they suggest that because it <em>should</em> have been high it should no longer be used as a metric.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/lowest.png" sizes="95vw"/> <img src="/assets/img/lowest.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="null-hacking">Null hacking??</h2> <p>During the investigation, the authors uploaded an apparently undisclosed sensitivity analysis of some sort (Decline effects/Decline effects - temporal decline and blinding.Rmd). The file appears last modified on March 15th, 2020 shortly after the earliest provided draft of the paper (March 14th, 2020). This code involved four different specifications from the preregistered model, evaluated in various ways: without the blinding effect, without self-replications, independent replications only, and controlling for independent replications.</p> <p>Although these analyses are not described in the published version, they appear to explore the possible model space to (generously) probe whether the results are consistent across model specifications. In the variation that ignores self-replications, the authors do find an interaction effect between wave and blinding that is significant and consistently so across model specifications (see below). It is unclear why the model space was explored so thoroughly and yet these analyses (and their conflicting results) were not included in the write-up. It also seems like there’s gotta be some name for running a model a bunch of different ways like a specification analysis and selectively presenting the null results. Oh wait, that’s Null Hacking <a href="https://osf.io/preprints/psyarxiv/9y3mp">(Protzko 2018)</a></p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/nullhacking.png" sizes="95vw"/> <img src="/assets/img/nullhacking.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="omission">Omission</h2> <p>Frankly, all of the above could probably be weaseled around. Is it really a formal analyses? These are just descriptives. Everyone engages in QRPs so what’s the big deal here? Maybe the results are still good? Isn’t this obviously true so who cares if the authors embraced all of those things the authors are arguing need to be eradicated for science to work…</p> <p>But here’s the <em>key</em> reason the findings couldn’t be trusted, even if you think everything above is a nothing-burger. It requires the tiniest bit of causal inference understanding, specifically that causes occur before effects.</p> <p>The paper contends that the authors discovered a set of highly replicable findings when using rigor-enhancing best practices. Because the discoveries occurred during the piloting phase, this can <em>only</em> be logically true if they followed the practices in piloting. Practices observed in replication cannot have caused the set of discoveries which were committed to before confirmation and replication.</p> <p>You can read more about the problem in depth as written <a href="http://users.eecs.northwestern.edu/~jhullman/Hullman_Protzko_et_al_comments.pdf">by Hullman</a>, who reviewed the Matters arising and the concerns. Tal Yarkoni, reviewing an earlier submission at Nature, pointed out the need to be transparent about the piloting process 4 years ago. Despite the centrality of the piloting to the effects discovered, the authors have refused to make information about pilots openly and transparently available. They have been silent in response to both Tal and Jessica’s concerns.</p> <p>As you read the paper, ask yourself the following questions:</p> <ul> <li>Did they verify all pilots were pre-registered and conducted without deviations?</li> <li>How many hypotheses were tested per pilot?</li> <li>Were they allowed to enter exploratory, post-hoc analyses based on trends in the pilot?</li> <li>What were the actual sample sizes of the pilots?</li> <li>Etc…</li> </ul> <p>Why is there so little clarity on the process that caused the discoveries? What few pilots I’ve found by weird google searches suggested they were free to test a bunch of outcomes and pick one of the hypotheses to pull forward. It’s clear they didn’t embrace the practice of large sample sizes (1500) in piloting. Worse, it seems they were free to embrace analytic flexibility during pilots as per a post of Nosek’s. He seems to suggest that rigor-enhancing best practices were not strictly required during the pilot–contrary to claims in the paper. We also get an indication that effect sizes declined where we’d expect them to and the authors really didn’t feel the need to mention this in the write-up.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/nosexplore.png" sizes="95vw"/> <img src="/assets/img/nosexplore.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Think about this for a second. If they found 16 hypotheses dredging out significant findings from some unstated number of n=200 experiments, committed to replicating them, and got 80% replicability or whatever… it implies that best practices are very much not needed to find replicable results. It seems you can data-dredge and hack significant findings from pilots at n=200, publish them and rest assured the replication crisis is over if the replicators use large sample sizes.</p> <p>This is a <em>Huge</em> question on which the entire paper depends. Tal Pointed it out in his review. James, their hired consultant, brought up the pilot selection problem in comments on drafts of the <a href="https://osf.io/rnvxk">original preregistration in ~2018</a>. Why ignore your hired statistican, reviewers, and the concerns that might retract your paper and <em>still</em> refuse to click “make public” on those pilot repositories? Their post-mortem suggests they’re analyzing the data, they must be organized somewhere, so why are they so reluctant to make them openly available?</p> <p>This was a key reason for retraction, as indicated in <a href="http://users.eecs.northwestern.edu/~jhullman/Hullman_Protzko_et_al_comments.pdf">Hullman’s review</a>. The authors have been aware of the concerns for 4-6 years. It was emphasized in our matters arising in raised in the concerns that prompted the investigation. Against this backdrop, it seems pretty damn misleading for their post-mortem to say:</p> <blockquote> <p>Also, our findings spurred interest in what occurred in the pilot phase of the project. We are likewise quite interested to learn more about the pilot phase.</p> </blockquote> <p>It is very difficult to square this with openness, honesty and transparency.</p> <h1 id="putting-it-all-together">Putting it all together</h1> <p>As I said at the outset. I had no desire to write this blog post. I didn’t want to wade into all of this. Their OSF is such a mess that getting claims straight and conveying them to others is a nightmare. Many of the links above will just open a massive zip file you’ll have to navigate to find the corresponding file. Good luck, go with god. Other parts of their repo including pilots of are unlinked and can only be found by searching on the internet archive, finding a registration and working your way back up—often to a still private repository. And despite the fact that embargos for many pilots should have lifted if they were actually preregistered, I can’t find most by searching in this manner. At times, preregistration seem to be little more than word documented uploaded to an OSF that they could easily remove or edit. Sometimes it’s just a description in a wiki.</p> <p>I have little doubt some will remain unconvinced because this post was tl;dr and the files are td;dr (too disorganized, didn’t read). I expect the authors and probably Lakens to try to seize on a thing or two I got wrong somewhere in here because the repo is a mess and they haven’t addressed any of these concerns. The inevitable bad faith response this will trigger is one of the very many reasons I did not want to write this post. I hate looking forward to some long screed of a blog post where a red square says “Oh but they measured replication in the only logical way to do so, I am not very impressed by Joe’s scientific abilities” or whatnot. Perhaps the authors saying they appreciate my concerns but disagree and will provide documentation. Same thing I’ve been hearing since November.</p> <p>All this is to say if I’m wrong about anything I’m happy to correct or amend. But even if one or two things could be written or framed differently, a lot would have to be wrong for it to meaningfully change the story. Still, if you doubt what’s above, rest assured that this is an abbreviated version of 20+ pages concerns I raised which were independently verified by a ten month investigation involving numerous domain and ethics experts.</p> <p>Whatever your thoughts, ask yourself: How many changes, updates, switched analyses, outcomes, rewrites would it take to call this more than just an “embarrassing mistake”? How many mistakes are we allowed until we cannot shrug them of brazenly? At what point should we be held accountable for allowing mistakes to accumulate over years despite repeated feedback? How many until we interpret their posts in the last few days as lies intended to cover up their actions.</p> <p>I summarized these concerns, and wrote the blog post I did not want to write. The authors forced my hand, after nearly a year of avoiding making this all public. I could wrote this post at any time, if my goal was just to sling mud. Yet their utterly misleading description of why the paper was retracted undermines my attempting to address this through the proper channels. It undermines the hundreds of hours experts spent unravelling this shit when they could have been doing literally anything else. Despite the extra work in comparison to slapping up a blog post, I reported these concerns formally, privately, and quietly because <em>I really did not want to write this post</em>.</p>]]></content><author><name></name></author><category term="metascience"/><category term="statistics"/><category term="retraction preregistration"/><category term="openscience"/><category term="preregistration"/><category term="metascience"/><summary type="html"><![CDATA[The Preregistration Revelation]]></summary></entry><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://joebakcoleman.com/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://joebakcoleman.com/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://joebakcoleman.com/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">a post with tabs</title><link href="https://joebakcoleman.com/blog/2024/tabs/" rel="alternate" type="text/html" title="a post with tabs"/><published>2024-05-01T00:32:13+00:00</published><updated>2024-05-01T00:32:13+00:00</updated><id>https://joebakcoleman.com/blog/2024/tabs</id><content type="html" xml:base="https://joebakcoleman.com/blog/2024/tabs/"><![CDATA[<p>This is how a post with <a href="https://github.com/Ovski4/jekyll-tabs">tabs</a> looks like. Note that the tabs could be used for different purposes, not only for code.</p> <h2 id="first-tabs">First tabs</h2> <p>To add tabs, use the following syntax:</p> <div class="language-liquid highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">{%</span><span class="w"> </span><span class="nt">tabs</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-1</span><span class="w"> </span><span class="cp">%}</span>

Content 1

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-2</span><span class="w"> </span><span class="cp">%}</span>

Content 2

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtabs</span><span class="w"> </span><span class="cp">%}</span>
</code></pre></div></div> <p>With this you can generate visualizations like:</p> <ul id="log" class="tab" data-tab="edf9c7a9-c9df-48e8-8da8-90b761b161ab" data-name="log"> <li class="active" id="log-php"> <a href="#">php </a> </li> <li id="log-js"> <a href="#">js </a> </li> <li id="log-ruby"> <a href="#">ruby </a> </li> </ul> <ul class="tab-content" id="edf9c7a9-c9df-48e8-8da8-90b761b161ab" data-name="log"> <li class="active"> <div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">var_dump</span><span class="p">(</span><span class="s1">'hello'</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">hello</span><span class="dl">"</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">pputs</span> <span class="dl">'</span><span class="s1">hello</span><span class="dl">'</span>
</code></pre></div></div> </li> </ul> <h2 id="another-example">Another example</h2> <ul id="data-struct" class="tab" data-tab="df5c815f-29dd-4fa3-a234-2601317c4b7f" data-name="data-struct"> <li class="active" id="data-struct-yaml"> <a href="#">yaml </a> </li> <li id="data-struct-json"> <a href="#">json </a> </li> </ul> <ul class="tab-content" id="df5c815f-29dd-4fa3-a234-2601317c4b7f" data-name="data-struct"> <li class="active"> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">hello</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">whatsup"</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">hi"</span>
</code></pre></div></div> </li> <li> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"hello"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"whatsup"</span><span class="p">,</span><span class="w"> </span><span class="s2">"hi"</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> </li> </ul> <h2 id="tabs-for-something-else">Tabs for something else</h2> <ul id="something-else" class="tab" data-tab="ec896752-e697-4044-9dce-c6c97d955be0" data-name="something-else"> <li class="active" id="something-else-text"> <a href="#">text </a> </li> <li id="something-else-quote"> <a href="#">quote </a> </li> <li id="something-else-list"> <a href="#">list </a> </li> </ul> <ul class="tab-content" id="ec896752-e697-4044-9dce-c6c97d955be0" data-name="something-else"> <li class="active"> <p>Regular text</p> </li> <li> <blockquote> <p>A quote</p> </blockquote> </li> <li> <p>Hipster list</p> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included tabs in a post could look like]]></summary></entry><entry><title type="html">a post with typograms</title><link href="https://joebakcoleman.com/blog/2024/typograms/" rel="alternate" type="text/html" title="a post with typograms"/><published>2024-04-29T23:36:10+00:00</published><updated>2024-04-29T23:36:10+00:00</updated><id>https://joebakcoleman.com/blog/2024/typograms</id><content type="html" xml:base="https://joebakcoleman.com/blog/2024/typograms/"><![CDATA[<p>This is an example post with some <a href="https://github.com/google/typograms/">typograms</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">+----+
|    |---&gt; My first diagram!
+----+</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-typograms">+----+
|    |---&gt; My first diagram!
+----+
</code></pre> <p>Another example:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.</span>
<span class="p">```</span>
</code></pre></div></div> <p>which generates:</p> <pre><code class="language-typograms">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.
</code></pre> <p>For more examples, check out the <a href="https://google.github.io/typograms/#examples">typograms documentation</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[this is what included typograms code could look like]]></summary></entry><entry><title type="html">a post that can be cited</title><link href="https://joebakcoleman.com/blog/2024/post-citation/" rel="alternate" type="text/html" title="a post that can be cited"/><published>2024-04-28T15:06:00+00:00</published><updated>2024-04-28T15:06:00+00:00</updated><id>https://joebakcoleman.com/blog/2024/post-citation</id><content type="html" xml:base="https://joebakcoleman.com/blog/2024/post-citation/"><![CDATA[<p>This is an example post that can be cited. The content of the post ends here, while the citation information is automatically provided below. The only thing needed is for you to set the <code class="language-plaintext highlighter-rouge">citation</code> key in the front matter to <code class="language-plaintext highlighter-rouge">true</code>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="citation"/><summary type="html"><![CDATA[this is what a post that can be cited looks like]]></summary></entry><entry><title type="html">a post with pseudo code</title><link href="https://joebakcoleman.com/blog/2024/pseudocode/" rel="alternate" type="text/html" title="a post with pseudo code"/><published>2024-04-15T00:01:00+00:00</published><updated>2024-04-15T00:01:00+00:00</updated><id>https://joebakcoleman.com/blog/2024/pseudocode</id><content type="html" xml:base="https://joebakcoleman.com/blog/2024/pseudocode/"><![CDATA[<p>This is an example post with some pseudo code rendered by <a href="https://github.com/SaswatPadhi/pseudocode.js">pseudocode</a>. The example presented here is the same as the one in the <a href="https://saswat.padhi.me/pseudocode.js/">pseudocode.js</a> documentation, with only one simple but important change: everytime you would use <code class="language-plaintext highlighter-rouge">$</code>, you should use <code class="language-plaintext highlighter-rouge">$$</code> instead. Also, note that the <code class="language-plaintext highlighter-rouge">pseudocode</code> key in the front matter is set to <code class="language-plaintext highlighter-rouge">true</code> to enable the rendering of pseudo code. As an example, using this code:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">pseudocode
</span><span class="sb">% This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\PROCEDURE{Quicksort}{$$A, p, r$$}
    \IF{$$p &lt; r$$}
        \STATE $$q = $$ \CALL{Partition}{$$A, p, r$$}
        \STATE \CALL{Quicksort}{$$A, p, q - 1$$}
        \STATE \CALL{Quicksort}{$$A, q + 1, r$$}
    \ENDIF
\ENDPROCEDURE
\PROCEDURE{Partition}{$$A, p, r$$}
    \STATE $$x = A[r]$$
    \STATE $$i = p - 1$$
    \FOR{$$j = p$$ \TO $$r - 1$$}
        \IF{$$A[j] &lt; x$$}
            \STATE $$i = i + 1$$
            \STATE exchange
            $$A[i]$$ with $$A[j]$$
        \ENDIF
        \STATE exchange $$A[i]$$ with $$A[r]$$
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Generates:</p> <pre><code class="language-pseudocode">% This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\PROCEDURE{Quicksort}{$$A, p, r$$}
    \IF{$$p &lt; r$$}
        \STATE $$q = $$ \CALL{Partition}{$$A, p, r$$}
        \STATE \CALL{Quicksort}{$$A, p, q - 1$$}
        \STATE \CALL{Quicksort}{$$A, q + 1, r$$}
    \ENDIF
\ENDPROCEDURE
\PROCEDURE{Partition}{$$A, p, r$$}
    \STATE $$x = A[r]$$
    \STATE $$i = p - 1$$
    \FOR{$$j = p$$ \TO $$r - 1$$}
        \IF{$$A[j] &lt; x$$}
            \STATE $$i = i + 1$$
            \STATE exchange
            $$A[i]$$ with $$A[j]$$
        \ENDIF
        \STATE exchange $$A[i]$$ with $$A[r]$$
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included pseudo code could look like]]></summary></entry><entry><title type="html">a post with code diff</title><link href="https://joebakcoleman.com/blog/2024/code-diff/" rel="alternate" type="text/html" title="a post with code diff"/><published>2024-01-27T19:22:00+00:00</published><updated>2024-01-27T19:22:00+00:00</updated><id>https://joebakcoleman.com/blog/2024/code-diff</id><content type="html" xml:base="https://joebakcoleman.com/blog/2024/code-diff/"><![CDATA[<p>You can display diff code by using the regular markdown syntax:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff
</span><span class="gh">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
</span><span class="gd">--- a/sample.js
</span><span class="gi">+++ b/sample.js
</span><span class="p">@@ -1 +1 @@</span>
<span class="gd">-console.log("Hello World!")
</span><span class="gi">+console.log("Hello from Diff2Html!")</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
</span><span class="gd">--- a/sample.js
</span><span class="gi">+++ b/sample.js
</span><span class="p">@@ -1 +1 @@</span>
<span class="gd">-console.log("Hello World!")
</span><span class="gi">+console.log("Hello from Diff2Html!")
</span></code></pre></div></div> <p>But this is difficult to read, specially if you have a large diff. You can use <a href="https://diff2html.xyz/">diff2html</a> to display a more readable version of the diff. For this, just use <code class="language-plaintext highlighter-rouge">diff2html</code> instead of <code class="language-plaintext highlighter-rouge">diff</code> for the code block language:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff2html
</span><span class="sb">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
--- a/sample.js
+++ b/sample.js
@@ -1 +1 @@
-console.log("Hello World!")
+console.log("Hello from Diff2Html!")</span>
<span class="p">```</span>
</code></pre></div></div> <p>If we use a longer example, for example <a href="https://github.com/rtfpessoa/diff2html/commit/c2c253d3e3f8b8b267f551e659f72b44ca2ac927">this commit from diff2html</a>, it will generate the following output:</p> <pre><code class="language-diff2html">From 2aaae31cc2a37bfff83430c2c914b140bee59b6a Mon Sep 17 00:00:00 2001
From: Rodrigo Fernandes &lt;rtfrodrigo@gmail.com&gt;
Date: Sun, 9 Oct 2016 16:41:54 +0100
Subject: [PATCH 1/2] Initial template override support

---
 scripts/hulk.js                    |  4 ++--
 src/diff2html.js                   |  3 +--
 src/file-list-printer.js           | 11 ++++++++---
 src/hoganjs-utils.js               | 29 +++++++++++++++++------------
 src/html-printer.js                |  6 ++++++
 src/line-by-line-printer.js        |  6 +++++-
 src/side-by-side-printer.js        |  6 +++++-
 test/file-list-printer-tests.js    |  2 +-
 test/hogan-cache-tests.js          | 18 +++++++++++++++---
 test/line-by-line-tests.js         |  3 +--
 test/side-by-side-printer-tests.js |  3 +--
 11 files changed, 62 insertions(+), 29 deletions(-)

diff --git a/scripts/hulk.js b/scripts/hulk.js
index 5a793c18..a4b1a4d5 100755
--- a/scripts/hulk.js
+++ b/scripts/hulk.js
@@ -173,11 +173,11 @@ function namespace(name) {
 // write a template foreach file that matches template extension
 templates = extractFiles(options.argv.remain)
   .map(function(file) {
-    var openedFile = fs.readFileSync(file, 'utf-8');
+    var openedFile = fs.readFileSync(file, 'utf-8').trim();
     var name;
     if (!openedFile) return;
     name = namespace(path.basename(file).replace(/\..*$/, ''));
-    openedFile = removeByteOrderMark(openedFile.trim());
+    openedFile = removeByteOrderMark(openedFile);
     openedFile = wrap(file, name, openedFile);
     if (!options.outputdir) return openedFile;
     fs.writeFileSync(path.join(options.outputdir, name + '.js')
diff --git a/src/diff2html.js b/src/diff2html.js
index 21b0119e..64e138f5 100644
--- a/src/diff2html.js
+++ b/src/diff2html.js
@@ -7,7 +7,6 @@

 (function() {
   var diffParser = require('./diff-parser.js').DiffParser;
-  var fileLister = require('./file-list-printer.js').FileListPrinter;
   var htmlPrinter = require('./html-printer.js').HtmlPrinter;

   function Diff2Html() {
@@ -43,7 +42,7 @@

     var fileList = '';
     if (configOrEmpty.showFiles === true) {
-      fileList = fileLister.generateFileList(diffJson, configOrEmpty);
+      fileList = htmlPrinter.generateFileListSummary(diffJson, configOrEmpty);
     }

     var diffOutput = '';
diff --git a/src/file-list-printer.js b/src/file-list-printer.js
index e408d9b2..1e0a2c61 100644
--- a/src/file-list-printer.js
+++ b/src/file-list-printer.js
@@ -8,11 +8,16 @@
 (function() {
   var printerUtils = require('./printer-utils.js').PrinterUtils;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var baseTemplatesPath = 'file-summary';
   var iconsBaseTemplatesPath = 'icon';

-  function FileListPrinter() {
+  function FileListPrinter(config) {
+    this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   FileListPrinter.prototype.generateFileList = function(diffFiles) {
@@ -38,5 +43,5 @@
     });
   };

-  module.exports.FileListPrinter = new FileListPrinter();
+  module.exports.FileListPrinter = FileListPrinter;
 })();
diff --git a/src/hoganjs-utils.js b/src/hoganjs-utils.js
index 9949e5fa..0dda08d7 100644
--- a/src/hoganjs-utils.js
+++ b/src/hoganjs-utils.js
@@ -8,18 +8,19 @@
 (function() {
   var fs = require('fs');
   var path = require('path');
-
   var hogan = require('hogan.js');

   var hoganTemplates = require('./templates/diff2html-templates.js');

-  var templatesPath = path.resolve(__dirname, 'templates');
+  var extraTemplates;

-  function HoganJsUtils() {
+  function HoganJsUtils(configuration) {
+    this.config = configuration || {};
+    extraTemplates = this.config.templates || {};
   }

-  HoganJsUtils.prototype.render = function(namespace, view, params, configuration) {
-    var template = this.template(namespace, view, configuration);
+  HoganJsUtils.prototype.render = function(namespace, view, params) {
+    var template = this.template(namespace, view);
     if (template) {
       return template.render(params);
     }
@@ -27,17 +28,16 @@
     return null;
   };

-  HoganJsUtils.prototype.template = function(namespace, view, configuration) {
-    var config = configuration || {};
+  HoganJsUtils.prototype.template = function(namespace, view) {
     var templateKey = this._templateKey(namespace, view);

-    return this._getTemplate(templateKey, config);
+    return this._getTemplate(templateKey);
   };

-  HoganJsUtils.prototype._getTemplate = function(templateKey, config) {
+  HoganJsUtils.prototype._getTemplate = function(templateKey) {
     var template;

-    if (!config.noCache) {
+    if (!this.config.noCache) {
       template = this._readFromCache(templateKey);
     }

@@ -53,6 +53,7 @@

     try {
       if (fs.readFileSync) {
+        var templatesPath = path.resolve(__dirname, 'templates');
         var templatePath = path.join(templatesPath, templateKey);
         var templateContent = fs.readFileSync(templatePath + '.mustache', 'utf8');
         template = hogan.compile(templateContent);
@@ -66,12 +67,16 @@
   };

   HoganJsUtils.prototype._readFromCache = function(templateKey) {
-    return hoganTemplates[templateKey];
+    return extraTemplates[templateKey] || hoganTemplates[templateKey];
   };

   HoganJsUtils.prototype._templateKey = function(namespace, view) {
     return namespace + '-' + view;
   };

-  module.exports.HoganJsUtils = new HoganJsUtils();
+  HoganJsUtils.prototype.compile = function(templateStr) {
+    return hogan.compile(templateStr);
+  };
+
+  module.exports.HoganJsUtils = HoganJsUtils;
 })();
diff --git a/src/html-printer.js b/src/html-printer.js
index 585d5b66..13f83047 100644
--- a/src/html-printer.js
+++ b/src/html-printer.js
@@ -8,6 +8,7 @@
 (function() {
   var LineByLinePrinter = require('./line-by-line-printer.js').LineByLinePrinter;
   var SideBySidePrinter = require('./side-by-side-printer.js').SideBySidePrinter;
+  var FileListPrinter = require('./file-list-printer.js').FileListPrinter;

   function HtmlPrinter() {
   }
@@ -22,5 +23,10 @@
     return sideBySidePrinter.generateSideBySideJsonHtml(diffFiles);
   };

+  HtmlPrinter.prototype.generateFileListSummary = function(diffJson, config) {
+    var fileListPrinter = new FileListPrinter(config);
+    return fileListPrinter.generateFileList(diffJson);
+  };
+
   module.exports.HtmlPrinter = new HtmlPrinter();
 })();
diff --git a/src/line-by-line-printer.js b/src/line-by-line-printer.js
index b07eb53c..d230bedd 100644
--- a/src/line-by-line-printer.js
+++ b/src/line-by-line-printer.js
@@ -11,7 +11,8 @@
   var utils = require('./utils.js').Utils;
   var Rematch = require('./rematch.js').Rematch;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var genericTemplatesPath = 'generic';
   var baseTemplatesPath = 'line-by-line';
   var iconsBaseTemplatesPath = 'icon';
@@ -19,6 +20,9 @@

   function LineByLinePrinter(config) {
     this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   LineByLinePrinter.prototype.makeFileDiffHtml = function(file, diffs) {
diff --git a/src/side-by-side-printer.js b/src/side-by-side-printer.js
index bbf1dc8d..5e3033b3 100644
--- a/src/side-by-side-printer.js
+++ b/src/side-by-side-printer.js
@@ -11,7 +11,8 @@
   var utils = require('./utils.js').Utils;
   var Rematch = require('./rematch.js').Rematch;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var genericTemplatesPath = 'generic';
   var baseTemplatesPath = 'side-by-side';
   var iconsBaseTemplatesPath = 'icon';
@@ -26,6 +27,9 @@

   function SideBySidePrinter(config) {
     this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   SideBySidePrinter.prototype.makeDiffHtml = function(file, diffs) {
diff --git a/test/file-list-printer-tests.js b/test/file-list-printer-tests.js
index a502a46f..60ea3208 100644
--- a/test/file-list-printer-tests.js
+++ b/test/file-list-printer-tests.js
@@ -1,6 +1,6 @@
 var assert = require('assert');

-var fileListPrinter = require('../src/file-list-printer.js').FileListPrinter;
+var fileListPrinter = new (require('../src/file-list-printer.js').FileListPrinter)();

 describe('FileListPrinter', function() {
   describe('generateFileList', function() {
diff --git a/test/hogan-cache-tests.js b/test/hogan-cache-tests.js
index 190bf6f8..3bb754ac 100644
--- a/test/hogan-cache-tests.js
+++ b/test/hogan-cache-tests.js
@@ -1,6 +1,6 @@
 var assert = require('assert');

-var HoganJsUtils = require('../src/hoganjs-utils.js').HoganJsUtils;
+var HoganJsUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)();
 var diffParser = require('../src/diff-parser.js').DiffParser;

 describe('HoganJsUtils', function() {
@@ -21,16 +21,28 @@ describe('HoganJsUtils', function() {
       });
       assert.equal(emptyDiffHtml, result);
     });
+
     it('should render view without cache', function() {
       var result = HoganJsUtils.render('generic', 'empty-diff', {
         contentClass: 'd2h-code-line',
         diffParser: diffParser
       }, {noCache: true});
-      assert.equal(emptyDiffHtml + '\n', result);
+      assert.equal(emptyDiffHtml, result);
     });
+
     it('should return null if template is missing', function() {
-      var result = HoganJsUtils.render('generic', 'missing-template', {}, {noCache: true});
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)({noCache: true});
+      var result = hoganUtils.render('generic', 'missing-template', {});
       assert.equal(null, result);
     });
+
+    it('should allow templates to be overridden', function() {
+      var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');
+
+      var config = {templates: {'generic-empty-diff': emptyDiffTemplate}};
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
   });
 });
diff --git a/test/line-by-line-tests.js b/test/line-by-line-tests.js
index 1cd92073..8869b3df 100644
--- a/test/line-by-line-tests.js
+++ b/test/line-by-line-tests.js
@@ -14,7 +14,7 @@ describe('LineByLinePrinter', function() {
         '            File without changes\n' +
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
-        '&lt;/tr&gt;\n';
+        '&lt;/tr&gt;';

       assert.equal(expected, fileHtml);
     });
@@ -422,7 +422,6 @@ describe('LineByLinePrinter', function() {
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
         '&lt;/tr&gt;\n' +
-        '\n' +
         '                &lt;/tbody&gt;\n' +
         '            &lt;/table&gt;\n' +
         '        &lt;/div&gt;\n' +
diff --git a/test/side-by-side-printer-tests.js b/test/side-by-side-printer-tests.js
index 76625f8e..771daaa5 100644
--- a/test/side-by-side-printer-tests.js
+++ b/test/side-by-side-printer-tests.js
@@ -14,7 +14,7 @@ describe('SideBySidePrinter', function() {
         '            File without changes\n' +
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
-        '&lt;/tr&gt;\n';
+        '&lt;/tr&gt;';

       assert.equal(expectedRight, fileHtml.right);
       assert.equal(expectedLeft, fileHtml.left);
@@ -324,7 +324,6 @@ describe('SideBySidePrinter', function() {
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
         '&lt;/tr&gt;\n' +
-        '\n' +
         '                    &lt;/tbody&gt;\n' +
         '                &lt;/table&gt;\n' +
         '            &lt;/div&gt;\n' +

From f3cadb96677d0eb82fc2752dc3ffbf35ca9b5bdb Mon Sep 17 00:00:00 2001
From: Rodrigo Fernandes &lt;rtfrodrigo@gmail.com&gt;
Date: Sat, 15 Oct 2016 13:21:22 +0100
Subject: [PATCH 2/2] Allow uncompiled templates

---
 README.md                 |  3 +++
 src/hoganjs-utils.js      |  7 +++++++
 test/hogan-cache-tests.js | 24 +++++++++++++++++++++++-
 3 files changed, 33 insertions(+), 1 deletion(-)

diff --git a/README.md b/README.md
index 132c8a28..46909f25 100644
--- a/README.md
+++ b/README.md
@@ -98,6 +98,9 @@ The HTML output accepts a Javascript object with configuration. Possible options
   - `synchronisedScroll`: scroll both panes in side-by-side mode: `true` or `false`, default is `false`
   - `matchWordsThreshold`: similarity threshold for word matching, default is 0.25
   - `matchingMaxComparisons`: perform at most this much comparisons for line matching a block of changes, default is `2500`
+  - `templates`: object with previously compiled templates to replace parts of the html
+  - `rawTemplates`: object with raw not compiled templates to replace parts of the html
+  &gt; For more information regarding the possible templates look into [src/templates](https://github.com/rtfpessoa/diff2html/tree/master/src/templates)

 ## Diff2HtmlUI Helper

diff --git a/src/hoganjs-utils.js b/src/hoganjs-utils.js
index 0dda08d7..b2e9c275 100644
--- a/src/hoganjs-utils.js
+++ b/src/hoganjs-utils.js
@@ -17,6 +17,13 @@
   function HoganJsUtils(configuration) {
     this.config = configuration || {};
     extraTemplates = this.config.templates || {};
+
+    var rawTemplates = this.config.rawTemplates || {};
+    for (var templateName in rawTemplates) {
+      if (rawTemplates.hasOwnProperty(templateName)) {
+        if (!extraTemplates[templateName]) extraTemplates[templateName] = this.compile(rawTemplates[templateName]);
+      }
+    }
   }

   HoganJsUtils.prototype.render = function(namespace, view, params) {
diff --git a/test/hogan-cache-tests.js b/test/hogan-cache-tests.js
index 3bb754ac..a34839c0 100644
--- a/test/hogan-cache-tests.js
+++ b/test/hogan-cache-tests.js
@@ -36,7 +36,7 @@ describe('HoganJsUtils', function() {
       assert.equal(null, result);
     });

-    it('should allow templates to be overridden', function() {
+    it('should allow templates to be overridden with compiled templates', function() {
       var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');

       var config = {templates: {'generic-empty-diff': emptyDiffTemplate}};
@@ -44,5 +44,27 @@ describe('HoganJsUtils', function() {
       var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
       assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
     });
+
+    it('should allow templates to be overridden with uncompiled templates', function() {
+      var emptyDiffTemplate = '&lt;p&gt;&lt;/p&gt;';
+
+      var config = {rawTemplates: {'generic-empty-diff': emptyDiffTemplate}};
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
+
+    it('should allow templates to be overridden giving priority to compiled templates', function() {
+      var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');
+      var emptyDiffTemplateUncompiled = '&lt;p&gt;Not used!&lt;/p&gt;';
+
+      var config = {
+        templates: {'generic-empty-diff': emptyDiffTemplate},
+        rawTemplates: {'generic-empty-diff': emptyDiffTemplateUncompiled}
+      };
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
   });
 });
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is how you can display code diffs]]></summary></entry><entry><title type="html">a post with advanced image components</title><link href="https://joebakcoleman.com/blog/2024/advanced-images/" rel="alternate" type="text/html" title="a post with advanced image components"/><published>2024-01-27T11:46:00+00:00</published><updated>2024-01-27T11:46:00+00:00</updated><id>https://joebakcoleman.com/blog/2024/advanced-images</id><content type="html" xml:base="https://joebakcoleman.com/blog/2024/advanced-images/"><![CDATA[<p>This is an example post with advanced image components.</p> <h2 id="image-slider">Image Slider</h2> <p>This is a simple image slider. It uses the <a href="https://swiperjs.com/">Swiper</a> library. Check the <a href="https://swiperjs.com/demos">examples page</a> for more information of what you can achieve with it.</p> <swiper-container keyboard="true" navigation="true" pagination="true" pagination-clickable="true" pagination-dynamic-bullets="true" rewind="true"> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/9.jpg" sizes="95vw"/> <img src="/assets/img/9.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/7.jpg" sizes="95vw"/> <img src="/assets/img/7.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/8.jpg" sizes="95vw"/> <img src="/assets/img/8.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/10.jpg" sizes="95vw"/> <img src="/assets/img/10.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/12.jpg" sizes="95vw"/> <img src="/assets/img/12.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> </swiper-container> <h2 id="image-comparison-slider">Image Comparison Slider</h2> <p>This is a simple image comparison slider. It uses the <a href="https://img-comparison-slider.sneas.io/">img-comparison-slider</a> library. Check the <a href="https://img-comparison-slider.sneas.io/examples.html">examples page</a> for more information of what you can achieve with it.</p> <img-comparison-slider> <figure slot="first"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic.jpg" sizes="95vw"/> <img src="/assets/img/prof_pic.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure slot="second"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic_color.png" sizes="95vw"/> <img src="/assets/img/prof_pic_color.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </img-comparison-slider>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what advanced image components could look like]]></summary></entry><entry><title type="html">a post with vega lite</title><link href="https://joebakcoleman.com/blog/2024/vega-lite/" rel="alternate" type="text/html" title="a post with vega lite"/><published>2024-01-27T00:20:00+00:00</published><updated>2024-01-27T00:20:00+00:00</updated><id>https://joebakcoleman.com/blog/2024/vega-lite</id><content type="html" xml:base="https://joebakcoleman.com/blog/2024/vega-lite/"><![CDATA[<p>This is an example post with some <a href="https://vega.github.io/vega-lite/">vega lite</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">vega_lite
</span><span class="sb">{
  "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
  "description": "A dot plot showing each movie in the database, and the difference from the average movie rating. The display is sorted by year to visualize everything in sequential order. The graph is for all Movies before 2019.",
  "data": {
    "url": "https://raw.githubusercontent.com/vega/vega/main/docs/data/movies.json"
  },
  "transform": [
    {"filter": "datum['IMDB Rating'] != null"},
    {"filter": {"timeUnit": "year", "field": "Release Date", "range": [null, 2019]}},
    {
      "joinaggregate": [{
        "op": "mean",
        "field": "IMDB Rating",
        "as": "AverageRating"
      }]
    },
    {
      "calculate": "datum['IMDB Rating'] - datum.AverageRating",
      "as": "RatingDelta"
    }
  ],
  "mark": "point",
  "encoding": {
    "x": {
      "field": "Release Date",
      "type": "temporal"
    },
    "y": {
      "field": "RatingDelta",
      "type": "quantitative",
      "title": "Rating Delta"
    },
    "color": {
      "field": "RatingDelta",
      "type": "quantitative",
      "scale": {"domainMid": 0},
      "title": "Rating Delta"
    }
  }
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-vega_lite">{
  "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
  "description": "A dot plot showing each movie in the database, and the difference from the average movie rating. The display is sorted by year to visualize everything in sequential order. The graph is for all Movies before 2019.",
  "data": {
    "url": "https://raw.githubusercontent.com/vega/vega/main/docs/data/movies.json"
  },
  "transform": [
    {"filter": "datum['IMDB Rating'] != null"},
    {"filter": {"timeUnit": "year", "field": "Release Date", "range": [null, 2019]}},
    {
      "joinaggregate": [{
        "op": "mean",
        "field": "IMDB Rating",
        "as": "AverageRating"
      }]
    },
    {
      "calculate": "datum['IMDB Rating'] - datum.AverageRating",
      "as": "RatingDelta"
    }
  ],
  "mark": "point",
  "encoding": {
    "x": {
      "field": "Release Date",
      "type": "temporal"
    },
    "y": {
      "field": "RatingDelta",
      "type": "quantitative",
      "title": "Rating Delta"
    },
    "color": {
      "field": "RatingDelta",
      "type": "quantitative",
      "scale": {"domainMid": 0},
      "title": "Rating Delta"
    }
  }
}
</code></pre> <p>This plot supports both light and dark themes.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included vega lite code could look like]]></summary></entry><entry><title type="html">a post with geojson</title><link href="https://joebakcoleman.com/blog/2024/geojson-map/" rel="alternate" type="text/html" title="a post with geojson"/><published>2024-01-26T17:57:00+00:00</published><updated>2024-01-26T17:57:00+00:00</updated><id>https://joebakcoleman.com/blog/2024/geojson-map</id><content type="html" xml:base="https://joebakcoleman.com/blog/2024/geojson-map/"><![CDATA[<p>This is an example post with some <a href="https://geojson.org/">geojson</a> code. The support is provided thanks to <a href="https://leafletjs.com/">Leaflet</a>. To create your own visualization, go to <a href="https://geojson.io/">geojson.io</a>.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">geojson
</span><span class="sb">{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "properties": {},
      "geometry": {
        "coordinates": [
          [
            [
              -60.11363029935569,
              -2.904625022183211
            ],
            [
              -60.11363029935569,
              -3.162613728707967
            ],
            [
              -59.820894493858034,
              -3.162613728707967
            ],
            [
              -59.820894493858034,
              -2.904625022183211
            ],
            [
              -60.11363029935569,
              -2.904625022183211
            ]
          ]
        ],
        "type": "Polygon"
      }
    }
  ]
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-geojson">{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "properties": {},
      "geometry": {
        "coordinates": [
          [
            [
              -60.11363029935569,
              -2.904625022183211
            ],
            [
              -60.11363029935569,
              -3.162613728707967
            ],
            [
              -59.820894493858034,
              -3.162613728707967
            ],
            [
              -59.820894493858034,
              -2.904625022183211
            ],
            [
              -60.11363029935569,
              -2.904625022183211
            ]
          ]
        ],
        "type": "Polygon"
      }
    }
  ]
}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><category term="maps"/><summary type="html"><![CDATA[this is what included geojson code could look like]]></summary></entry></feed>